{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial\n",
    "\n",
    "PyTorch is a Python-based scientific computing package.\n",
    "\n",
    "The fundamental PyTorch concept is the __Tensor__, which is conceptually identical to a numpy array, i.e. an $n$-dimensional array. \n",
    "\n",
    "> __Like numpy array__ a PyTorch Tensor is a generic tool for scientific computing.\n",
    "\n",
    "> __Unlike numpy array__ a PyTorch Tensor can use GPU to accelerate numeric computations. \n",
    "\n",
    "Moreover, PyTorch is a deep learning research platform that provides maximum flexibility and speed.\n",
    "\n",
    "## Tensor\n",
    "For further details, see https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.9265e-26,  4.5905e-41,  1.7983e-37],\n",
      "        [ 0.0000e+00, -2.2659e+22,  4.5904e-41],\n",
      "        [-1.5273e-31,  4.5905e-41, -2.4139e+22],\n",
      "        [ 4.5904e-41, -2.2880e+22,  4.5904e-41],\n",
      "        [-2.2658e+22,  4.5904e-41,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "##Construct a 5x3 matrix, uninitialized\n",
    "m = torch.empty(5, 3)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3014,  0.1197,  0.2546],\n",
      "        [ 0.6978,  0.6679,  0.8752],\n",
      "        [ 0.9055,  0.3034,  0.7594],\n",
      "        [ 0.3435,  0.0665,  0.6568],\n",
      "        [ 0.7785,  0.8107,  0.6746]])\n"
     ]
    }
   ],
   "source": [
    "##Construct a 5x3 matrix, randomly initialized\n",
    "m = torch.rand(5, 3)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "##Construct a 5x3 matrix filled with zeros and of dtype Long (i.e. integers)\n",
    "m = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2],\n",
      "        [ 3,  4]])\n"
     ]
    }
   ],
   "source": [
    "##Construct a 2x2 tensor directly from data (1:4 int)\n",
    "x = torch.tensor([[1, 2],[3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "tensor([[ 0.2629,  0.8436,  0.1544],\n",
      "        [ 0.9891,  0.6040,  0.5990],\n",
      "        [ 0.5468,  0.8771,  0.3769],\n",
      "        [ 0.2685,  0.9077,  0.8635],\n",
      "        [ 0.0102,  0.7071,  0.9677]])\n"
     ]
    }
   ],
   "source": [
    "##Create a 5x3 tensor of 1s, dtype double, from an existing one\n",
    "x = x.new_ones(5, 3, dtype=torch.double) ##new_* method\n",
    "print(x)\n",
    "##Transform the tensor above in a random tensor of dtype = float\n",
    "x = torch.rand_like(x, dtype = torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "##get a tensor size\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8603,  1.9029,  1.7428],\n",
       "        [ 1.2551,  1.2597,  1.4212],\n",
       "        [ 1.3318,  1.0015,  1.6525],\n",
       "        [ 1.1707,  1.3352,  1.2722],\n",
       "        [ 1.8411,  1.3074,  1.0169]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sum two tensors x and y of size 5x3\n",
    "##Syntax 1\n",
    "x = torch.ones(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8603,  1.9029,  1.7428],\n",
      "        [ 1.2551,  1.2597,  1.4212],\n",
      "        [ 1.3318,  1.0015,  1.6525],\n",
      "        [ 1.1707,  1.3352,  1.2722],\n",
      "        [ 1.8411,  1.3074,  1.0169]])\n"
     ]
    }
   ],
   "source": [
    "##Syntax 2\n",
    "torch.add(x, y)\n",
    "###save the result in a new tensor (previously defined)\n",
    "z = torch.empty(5, 3)\n",
    "torch.add(x, y, out=z)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8603,  1.9029,  1.7428],\n",
      "        [ 1.2551,  1.2597,  1.4212],\n",
      "        [ 1.3318,  1.0015,  1.6525],\n",
      "        [ 1.1707,  1.3352,  1.2722],\n",
      "        [ 1.8411,  1.3074,  1.0169]])\n"
     ]
    }
   ],
   "source": [
    "##In-place addition, substitute y with x+y\n",
    "y.add_(x)\n",
    "print(y) ##in-places operations are post-fixed with _ (e.g. x.t_() transposes tensor x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6207,  0.1739,  0.5064,  0.2268,  0.1664])\n"
     ]
    }
   ],
   "source": [
    "##Indexing Tensors\n",
    "x = torch.rand(5, 3)\n",
    "print(x[:, 1]) ##returns the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([[-0.3076, -1.3366,  0.1111, -0.3400],\n",
      "        [ 0.7326, -0.5380,  0.0312, -1.5047],\n",
      "        [-0.7740,  0.0863,  0.1955,  0.7107],\n",
      "        [ 0.0028, -0.4003, -0.4130,  0.0655]]) tensor([-0.3076, -1.3366,  0.1111, -0.3400,  0.7326, -0.5380,  0.0312,\n",
      "        -1.5047, -0.7740,  0.0863,  0.1955,  0.7107,  0.0028, -0.4003,\n",
      "        -0.4130,  0.0655]) tensor([[-0.3076, -1.3366,  0.1111, -0.3400,  0.7326, -0.5380,  0.0312,\n",
      "         -1.5047],\n",
      "        [-0.7740,  0.0863,  0.1955,  0.7107,  0.0028, -0.4003, -0.4130,\n",
      "          0.0655]])\n"
     ]
    }
   ],
   "source": [
    "##Tensor RESIZING\n",
    "x = torch.randn(4, 4)\n",
    "##(4x4) --> (16)\n",
    "y = x.view(16)\n",
    "##(4x4) --> (2x8)\n",
    "z = x.view(2, -1) ##once the first dimension is fixed, the second is automatically given if -1\n",
    "print(x.size(), y.size(), z.size())\n",
    "print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9504])\n",
      "0.9503579139709473\n"
     ]
    }
   ],
   "source": [
    "##return the value of a Tensor of dimension 1 as a Python number\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "##Convert a tensor to a numpy array\n",
    "a = torch.ones(5, 3)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.]])\n",
      "[[2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "##Add 1 to the tensor a\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b) ##observe how the numpy array changed in value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "##convert NumPy array to PyTorch tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "##add 1 to a\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b) ##watch how the Tensor changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9335,  1.1431,  1.7024],\n",
      "        [ 0.8835,  1.4194,  2.8523],\n",
      "        [ 1.3923,  1.0960,  1.6698],\n",
      "        [-0.2573,  0.6276,  0.6845],\n",
      "        [ 0.9801,  0.8895,  2.4119]], device='cuda:2')\n",
      "tensor([[ 0.9335,  1.1431,  1.7024],\n",
      "        [ 0.8835,  1.4194,  2.8523],\n",
      "        [ 1.3923,  1.0960,  1.6698],\n",
      "        [-0.2573,  0.6276,  0.6845],\n",
      "        [ 0.9801,  0.8895,  2.4119]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "##check if the CUDA device is available \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2') \n",
    "    y = torch.ones_like(x, device=device) ##move x and y to cuda\n",
    "    x = x.to(device) ##tensors can be moved onto any device using the .to method\n",
    "    z = x + y ##z is stored in cuda\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double)) ##move z to the cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torch.cuda.device object at 0x7ff6e49306d8>\n",
      "4\n",
      "Graphics Device\n"
     ]
    }
   ],
   "source": [
    "##useful methods that can be called to inspect the devices\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: automatic differentiation\n",
    "For further details, see https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "\n",
    "The `autograd` package provides automatic differentiation for all the operations on tensors.\n",
    "\n",
    "`requires_grad` is an attribute of the class `torch.Tensor`. If `requires_grad=True`, then all the operations on the tensor are tracked. Once the computation is finished, the method `.backward()` can be called, and the gradients are automatically computed. The gradient for the tensor is accumulated into `.grad` attribute.\n",
    "\n",
    "A very important class for autograd implementation is `Function`. The classes `Tensor` and `Function` are interconnected, and build up an acyclic graph that encodes a complete hystory of computations. The variable that results from computation has an attribute `grad_fn`, that references a `Function` that has created the `Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3303,  0.7276,  0.7925],\n",
      "        [ 0.2868,  0.1420,  0.4408],\n",
      "        [ 0.3899,  0.2825,  0.2112],\n",
      "        [ 0.8884,  0.9656,  0.3476],\n",
      "        [ 0.9990,  0.7865,  0.2785]])\n",
      "tensor([[ 1.3303,  1.7276,  1.7925],\n",
      "        [ 1.2868,  1.1420,  1.4408],\n",
      "        [ 1.3899,  1.2825,  1.2112],\n",
      "        [ 1.8884,  1.9656,  1.3476],\n",
      "        [ 1.9990,  1.7865,  1.2785]])\n",
      "<AddBackward1 object at 0x7f42ebb9a438>\n"
     ]
    }
   ],
   "source": [
    "##Create a tensor and track the computations\n",
    "x = torch.rand(5, 3, requires_grad=True)\n",
    "##Do an operation on tensors\n",
    "y = torch.ones(5, 3)\n",
    "z = x+y\n",
    "print(z)\n",
    "\n",
    "##z is the result of an operation between tensors, hence it has the attribute grad_fn\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "##requires_grad defaults to True, change the flag in-place for tensor y\n",
    "y.requires_grad_(False)\n",
    "h = y + 2\n",
    "print(h.grad_fn) ##the attribute is None cause no operation has been tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "##Execute a whole block without tracking the operations on tensors\n",
    "with torch.no_grad():\n",
    "    x = torch.ones(5, 3)\n",
    "    y = x + 2\n",
    "    print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  27.,  27.],\n",
      "        [ 27.,  27.,  27.],\n",
      "        [ 27.,  27.,  27.],\n",
      "        [ 27.,  27.,  27.],\n",
      "        [ 27.,  27.,  27.]])\n",
      "tensor([[ 1.2000,  1.2000,  1.2000],\n",
      "        [ 1.2000,  1.2000,  1.2000],\n",
      "        [ 1.2000,  1.2000,  1.2000],\n",
      "        [ 1.2000,  1.2000,  1.2000],\n",
      "        [ 1.2000,  1.2000,  1.2000]])\n"
     ]
    }
   ],
   "source": [
    "##Compute the gradient of a scalar\n",
    "x = torch.ones(5, 3, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "\n",
    "out = z.mean()\n",
    "print(z) ##z is a scalar\n",
    "\n",
    "out.backward() ##out = sum_i[(x_i+2)^2 * 3]/15, we are computing d(out)/dx_i for each i\n",
    "print(x.grad) ##result stored in x's attribute .grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2991,  0.6440,  0.8020,  0.8198,  0.9514])\n",
      "tensor([ 0.6877,  1.7027,  2.2470,  2.3116,  2.8078])\n",
      "tensor([ 2.5982,  6.5760,  3.6039,  3.6395,  3.9027])\n"
     ]
    }
   ],
   "source": [
    "##Compute the gradient of a tensor\n",
    "x = torch.rand(5, requires_grad=True)\n",
    "y = x * 2 + x ** 2\n",
    "\n",
    "print(x)\n",
    "print(y) ##y = [2x_1, 2x_2, ..., 2x_5]\n",
    "gradient = torch.tensor([1., 2., 1., 1., 1.]) ##we need to specify a gradient argument\n",
    "\n",
    "y.backward(gradient) ## dy/dx = [1*(2*0.299+2), 2*(2*0.64+2),...]\n",
    "print(x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
