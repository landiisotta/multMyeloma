{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) __Embedding__ of medical terms (`nn.Embedding(vocab_size, embedding_dim)`):\n",
    "\n",
    "$$\n",
    "E \\in \\mathbb{R}^{T\\times d}\n",
    "$$\n",
    "\n",
    "where $T$ is the time at which the medical terms were collected and $d$ is the _embedding dimension_.\n",
    "\n",
    "We obtain a tensor of size:\n",
    "```\n",
    "torch.Size([T, d])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) __Multidimensional matrix__\n",
    "\n",
    "$$\n",
    "W \\in \\mathbb{R}^{1\\times T \\times d}\n",
    "$$\n",
    "\n",
    "Basically we have a vector of length $T$ with $d$ channels.\n",
    "\n",
    "```\n",
    "embeds = embeds.view(1, self.embedding_dim, -1) \n",
    "```\n",
    "\n",
    "In this way we prepare the tensor for the 1-dimensional convolution, which takes as input $(N,C_{in},L_{in})$, where $N$ is the batch size, $C_{in}$ is the number of input channels and $L_{in}$ is the sequence length. \n",
    "\n",
    "```\n",
    "torch.Size([1, d, T])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) __Convolution__\n",
    "\n",
    "One-dimensional convolution \n",
    "\n",
    "```\n",
    "self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=kernel_size, padding=(kernel_size - 1)/2)\n",
    "```\n",
    "\n",
    "With padding equal to $\\frac{(k-1)}{2}$, where $k$ is the filter dimension, we obtain an output with length equal to the input (i.e. $L_{in} = L_{out}$), if _stride_ and _dilation_ are equal to 1.\n",
    "\n",
    "The `Conv1d` class is instantiated with the input and output channels as the first two arguments.\n",
    "\n",
    "Hence, we obtain a tensor:\n",
    "```\n",
    "torch.Size([1, d, T])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark1:__ in this way the channels, i.e. the embedding dimensions, are kept separate. This can be useful if we try to preserve the original dimension as long as possible. We need to remember this when we input the data to the autoencoder.\n",
    "\n",
    "__Remark2:__ all these passages are done with `batch_size=1` in order to preserve as long as possible the different time stamps. \n",
    "\n",
    "__Remark3:__ check the classical architecture of 1-dimensional CNN.\n",
    "\n",
    "__Remark4:__ one way to solve the different dimensions problem is to apply a convolution that makes the output bigger (_dilation_?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ehrModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, kernel_size, k_max):\n",
    "        super(ehrModel, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.k_max = k_max\n",
    "        padding = int((kernel_size-1)/2)\n",
    "        \n",
    "        #Embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        ##Convolution\n",
    "        self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=kernel_size, padding=padding)\n",
    "        self.FC = nn.Linear(embedding_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        embeds_mat = embeds\n",
    "        print(embeds[0])\n",
    "        print(\"Embedding dimension: {0}\".format(embeds.shape))\n",
    "        embeds = embeds.view(1, self.embedding_dim, -1)\n",
    "        print(\"Reshaping before convolution: {0}\".format(embeds.shape))\n",
    "        out = self.cnn(embeds)\n",
    "        print(out[0][0])\n",
    "        print(\"CNN: {0}\".format(out.shape))\n",
    "        out = F.relu(out)\n",
    "        print(\"ReLU: {0}\".format(out.shape))\n",
    "        out = F.max_pool1d(out, kernel_size) \n",
    "        print(\"Pooling: {0}\".format(out.shape))\n",
    "        out = self.cnn(out)\n",
    "        print(out[0][0])\n",
    "        out = F.relu(out)\n",
    "        print(\"RELU(CNN): {0}\".format(out.shape))\n",
    "        out = out.view(-1, embedding_dim)\n",
    "        print(\"Reshape: {0}\".format(out.shape))\n",
    "        out = self.kmaxPooling(out, self.k_max)[0]\n",
    "        print(\"KMAXpool: {0}\".format(out.shape))\n",
    "        out = out.view(-1, self.embedding_dim)\n",
    "        print(\"Reshaping: {0}\".format(out.shape))\n",
    "        out = F.relu(self.FC(out))\n",
    "        print(\"ReLU + FC: {0}\".format(out.shape))\n",
    "        pre_out = out\n",
    "        out = out.view(-1)\n",
    "        print(\"Before AE: {0}\".format(out.shape))\n",
    "        print(embeds.shape[2])\n",
    "        ehrAE = ae(self.embedding_dim, embeds.shape[2])\n",
    "        encoded_vect, out = ehrAE(out)\n",
    "        print(\"Encoded: {0}\".format(encoded_vect.shape))\n",
    "        print(\"Reconstruction: {0}\".format(out.shape))\n",
    "        \n",
    "        return(embeds_mat, out)\n",
    "        \n",
    "    def kmaxPooling(self, x, k):\n",
    "        return torch.topk(x, k, dim=0, sorted=False) #returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4])\n",
      "tensor([[[ 4,  3,  2],\n",
      "         [ 6,  5,  4]],\n",
      "\n",
      "        [[ 4,  3,  2],\n",
      "         [ 6,  5,  4]]]) torch.Size([2, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3,4], [4,5,6,2]], [[1,2,3,4], [4,5,6,2]]])\n",
    "print(a.shape)\n",
    "\n",
    "a = torch.topk(a, 3)[0]\n",
    "print(a, a.shape)\n",
    "a = a.view(-1, 6)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Autoencoder\n",
    "class ae(nn.Module):\n",
    "    def __init__(self, d, c_size):\n",
    "        super(ae, self).__init__()\n",
    "        self.c_size = c_size\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(d * d, int(d/2)),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(int(d/2), 1),\n",
    "        nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.Linear(1, int(d/2)),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(int(d/2), d * d),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(d * d, c_size * d))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        encoded_vect = x\n",
    "        x = self.decoder(x)\n",
    "        return(encoded_vect, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supponiamo di avere tre pazienti con EHRs di lunghezze diverse \n",
    "#vogliamo applicare CBOW considerando il contesto K (user-defined) separatamente per ogni \"sentence\",\n",
    "#cioe' separatamente per ogni paziente\n",
    "#Creiamo one list with different arrays storing the tokens of the medical terms\n",
    "# one array for each patient\n",
    "P1 = \"A wiki is run using wiki software, otherwise known as a wiki engine.\\\n",
    "         A wiki engine is a type of content management system, but it differs\\\n",
    "         from most other such systems, including blog software, in that the\\\n",
    "         content is created without any defined owner or leader, and wikis have\\\n",
    "         little implicit structure, allowing structure to emerge according to the\\\n",
    "         needs of the users.\"\n",
    "\n",
    "P2 = \"The online encyclopedia project Wikipedia is by far the most popular wiki-based\\\n",
    "         website, and is one of the most widely viewed sites of any kind in the world,\\\n",
    "         having been ranked in the top ten since 2007.\"\n",
    "\n",
    "P3 = \"Wikipedia is not a single wiki but rather a collection of hundreds of wikis,\\\n",
    "         one for each language. There are tens of thousands of other wikis in use, both\\\n",
    "         public and private, including wikis functioning as knowledge management resources,\\\n",
    "         notetaking tools, community websites and intranets. The English-language Wikipedia\\\n",
    "         has the largest collection of articles; as of September 2016, it had over five\\\n",
    "         million articles.\"\n",
    "\n",
    "##ARRAY with tokens from patients\n",
    "H = [P1.split(), P2.split(), P3.split()]\n",
    "\n",
    "##Fun1: creiamo il nostro dictionary (associamo univocamente un token a un intero)\n",
    "##Input: array of sentences\n",
    "def create_dict(array_sentences): \n",
    "    word_to_ix = {}\n",
    "    ix_to_word = {}\n",
    "    \n",
    "    for _, j in enumerate(array_sentences):\n",
    "        for word in j:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                ix_to_word[len(ix_to_word)] = word\n",
    "    return word_to_ix, ix_to_word\n",
    "\n",
    "word_to_ix, ix_to_word = create_dict(H)\n",
    "\n",
    "data = [[word_to_ix[mt] for mt in a] for _, a in enumerate(H)]\n",
    "\n",
    "vocab_size = len(word_to_ix)\n",
    "embedding_dim = 10\n",
    "kernel_size = 3\n",
    "k_max = 10\n",
    "\n",
    "model = ehrModel(vocab_size, embedding_dim, kernel_size, k_max)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "##in order to compute the gradient with respect to both the input and the output:\n",
    "def mse_loss(input, target):\n",
    "    return torch.sum((input - target)**2) / input.data.nelement()\n",
    "\n",
    "a = torch.tensor([[1,2,3],[1,2,3]])\n",
    "a.shape\n",
    "\n",
    "for epoch in range(5):\n",
    "    for i, d in enumerate(data):\n",
    "        print(\"vect {0:1d}\".format(i))\n",
    "        embeds, out = model(torch.tensor(d))\n",
    "    \n",
    "        MSE_loss = mse_loss(embeds, out.view(embeds.shape[0], -1))\n",
    "        print(\"MSE loss: {0}\".format(MSE_loss))\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        MSE_loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5638cfc292f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testData' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        test_loss = 0.0\n",
    "        for d in testData:\n",
    "            pre, out = model(torch.tensor(d))\n",
    "            loss = mse_loss(pre, out)\n",
    "            test_loss += loss.item()\n",
    "        test_loss = test_loss/len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09958014823496342"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = \"A wiki engine is a type of content management system, but it differs\\\n",
    "         from most other such systems, including blog software, in that the\\\n",
    "         content is created without any defined owner or leader, and wikis have\"\n",
    "    \n",
    "T2 = \"one for each language. There are tens of thousands of other wikis in use, both\\\n",
    "         public and private, including wikis functioning as knowledge management resources,\\\n",
    "         notetaking tools, community websites and intranets. The English-language Wikipedia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [T1.split(), T2.split()]\n",
    "testData = [[word_to_ix[mt] for mt in a] for _, a in enumerate(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = torch.tensor([[[1,2,3], [4,5,6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = prova.view(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4],\n",
       "        [ 2,  5],\n",
       "        [ 3,  6]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova.t_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4],\n",
       "        [ 2,  5],\n",
       "        [ 3,  6]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
