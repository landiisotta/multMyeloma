{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalchbrenner, N. 2014\n",
    "Convolution operation followed by a pooling operation. \n",
    "\n",
    "- start with a projected sentence matrix of size $d\\times s$, where $d$ is the embedding dimension and $s$ is the number of words ($\\mathbf{w}_i$) in the sentence $\\mathbf{s}$. The values in the embeddings $\\mathbf{w}_i$ are parameters that are optimized during training.  \n",
    "- Convolutional layer: convolves a matrix of weights $\\mathbf{m} \\in \\mathbb{R}^{d\\times m}$ with the matrix at the layer below.\n",
    "- Resulting matrix $\\mathbf{c} \\in \\mathbb{R}^{d\\times (s+m-1)}$.\n",
    "- $k-\\max$ pooling (_dynamic_) is applied. Given a value $k$ and a sequence $\\mathbf{p}\\in \\mathbb{R}^{p}$, with $p\\geq k$, $k-\\max$ pooling selects the subsequence $\\mathbf{p}^k_{\\max}$ of the $k$ highest values of $\\mathbf{p}$. This guarantees that the input of the fully connected layers is independent of the length of the input sentence.\n",
    "- a bias $\\mathbf{b}\\in\\mathbb{R}^d$ and a non-linear function $g$ are applied component-wise to the pooled matrix. (_Fully connected layer_)\n",
    "- Folding: between convolution and pooling in the last layer. Sum of every two rows component-wise in a feature map. Hence, dimension $d$ is halved ($d/2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context] ##word_to_ix is the dictionary with words in text and numbers\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return tensor\n",
    "\n",
    "def get_index_max(input):\n",
    "    index = 0\n",
    "    for i in range(1, len(input)):\n",
    "        if input[i] > input[index]:\n",
    "            index = i\n",
    "        return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "We can start by considering the whole EHR of a patient as a sentence.\n",
    "1. embedding\n",
    "2. CNN: wide convolution with `kMaxPooling`.\n",
    "3. AE: autoencoder whose code dimension is less than the input dimension (__undercomplete__). We want to learn an undercomplete representation of the training data in order to capture their most salient features. The learning process is described simply as minimizing a loss function\n",
    "$$\n",
    "L(\\mathbf{x}, g(f(\\mathbf{x})))\n",
    "$$\n",
    "where L is a loss function penalizing $g(f(\\mathbf{x}))$ for being dissimilar from $\\mathbf{x}$ (e.g. mean squared error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the hidden layer after a convolution is $\\frac{(W-F+2P)}{S}+1$, where $W$ is the first layer size, $F$ is the filter size, $P$ is the padding and $S$ is the stride. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ehrStrat(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, kernel_size, word_to_ix, ix_to_word, k_max1, k_max2):\n",
    "        super(ehrStrat, self).__init__()\n",
    "        self.k_max1 = k_max1\n",
    "        self.k_max2 = k_max2\n",
    "        self.word_to_ix = word_to_ix\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.cnn = nn.Conv1d(embedding_dim, embedding_dim, kernel_size=kernel_size, padding=1)\n",
    "        self.cnn2 = nn.Conv1d(1, 1, kernel_size=(kernel_size, 1), padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        print(embeds.shape)\n",
    "        embeds = embeds.view(1, self.embedding_dim, -1)                     \n",
    "        #embeds = embeds.view(1,1,-1, self.embedding_dim)\n",
    "        print(embeds, embeds.shape)\n",
    "        out = self.cnn(embeds)\n",
    "        print(out, out.shape)\n",
    "        out = out.view(out.shape[2], out.shape[3])\n",
    "        print(out, out.shape)\n",
    "        out = self.kmaxPooling(out, self.k_max1)[0]\n",
    "        out = out.view(1, 1, self.k_max1, 1)\n",
    "        out = self.cnn2(out)\n",
    "        out = out.view(out.shape[2])\n",
    "        print(out, out.shape)\n",
    "        out = self.kmaxPooling(out, self.k_max2)[0]\n",
    "        out = out.view(1, 1, self.k_max2, 1)\n",
    "        d = out.shape[2] * out.shape[3]\n",
    "        out = out.view(d)\n",
    "        print(out.shape)\n",
    "        ehrAE = ae(d)\n",
    "        pre_vec = out\n",
    "        out = ehrAE(out) \n",
    "        \n",
    "        return pre_vec, out\n",
    "        \n",
    "    def kmaxPooling(self, x, k):\n",
    "        return torch.topk(x, k, dim=0, sorted=False) #returns \n",
    "    \n",
    "    def get_word_embedding(self, word):\n",
    "        word = torch.LongTensor([word_to_ix[word]])\n",
    "        return self.embedding(word).view(1, -1)\n",
    "    \n",
    "    def pat_embedding(self, sentence, emb_dim):\n",
    "        mat_all = []\n",
    "        emb = torch.empty(len(sentence), emb_dim)\n",
    "\n",
    "        for num in sentence:\n",
    "            for med_term in sentence:\n",
    "                emb = torch.cat((emb, self.get_word_embedding(ix_to_word[med_term]).detach()),0)\n",
    "            mat_all += [emb]\n",
    "\n",
    "        return mat_all\n",
    "#k-max pooling so the matrix has the same size for each patient\n",
    "#heredit ae class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder and decoder are still trained together, but once we have the weights, we can use the two separately — maybe we use the encoder to generate a more meaningful representation of some data we’re feeding into another neural network, or the decoder to let the network generate new data we haven’t shown it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ae(nn.Module):\n",
    "    def __init__(self, d):\n",
    "        super(ae, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(d, 20),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(20, 10),\n",
    "        nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.Linear(10, 20),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(20, d))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supponiamo di avere tre pazienti con EHRs di lunghezze diverse \n",
    "#vogliamo applicare CBOW considerando il contesto K (user-defined) separatamente per ogni \"sentence\",\n",
    "#cioe' separatamente per ogni paziente\n",
    "#Creiamo one list with different arrays storing the tokens of the medical terms\n",
    "# one array for each patient\n",
    "P1 = \"A wiki is run using wiki software, otherwise known as a wiki engine.\\\n",
    "         A wiki engine is a type of content management system, but it differs\\\n",
    "         from most other such systems, including blog software, in that the\\\n",
    "         content is created without any defined owner or leader, and wikis have\\\n",
    "         little implicit structure, allowing structure to emerge according to the\\\n",
    "         needs of the users.\"\n",
    "\n",
    "P2 = \"The online encyclopedia project Wikipedia is by far the most popular wiki-based\\\n",
    "         website, and is one of the most widely viewed sites of any kind in the world,\\\n",
    "         having been ranked in the top ten since 2007.\"\n",
    "\n",
    "P3 = \"Wikipedia is not a single wiki but rather a collection of hundreds of wikis,\\\n",
    "         one for each language. There are tens of thousands of other wikis in use, both\\\n",
    "         public and private, including wikis functioning as knowledge management resources,\\\n",
    "         notetaking tools, community websites and intranets. The English-language Wikipedia\\\n",
    "         has the largest collection of articles; as of September 2016, it had over five\\\n",
    "         million articles.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ARRAY with tokens from patients\n",
    "H = [P1.split(), P2.split(), P3.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fun1: creiamo il nostro dictionary (associamo univocamente un token a un intero)\n",
    "##Input: array of sentences\n",
    "def create_dict(array_sentences): \n",
    "    word_to_ix = {}\n",
    "    ix_to_word = {}\n",
    "    \n",
    "    for _, j in enumerate(array_sentences):\n",
    "        for word in j:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "                ix_to_word[len(ix_to_word)] = word\n",
    "    return word_to_ix, ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix, ix_to_word = create_dict(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[word_to_ix[mt] for mt in a] for _, a in enumerate(H)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 1, 5, 6, 7, 8, 9, 1, 10, 0, 1, 11, 2, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 5, 27, 28, 29, 14, 2, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 45, 29, 48, 13, 29, 49]\n",
      "[50, 51, 52, 53, 54, 2, 55, 56, 29, 21, 57, 58, 59, 37, 2, 60, 13, 29, 21, 61, 62, 63, 13, 32, 64, 27, 29, 65, 66, 67, 68, 27, 29, 69, 70, 71, 72]\n",
      "[54, 2, 73, 9, 74, 1, 17, 75, 9, 76, 13, 77, 13, 78, 60, 79, 80, 81, 82, 83, 84, 13, 85, 13, 22, 38, 27, 86, 87, 88, 37, 89, 25, 38, 90, 8, 91, 15, 92, 93, 94, 95, 96, 37, 97, 50, 98, 54, 99, 29, 100, 76, 13, 101, 8, 13, 102, 103, 18, 104, 105, 106, 107, 108]\n"
     ]
    }
   ],
   "source": [
    "for sequence in data:\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 10\n",
    "vocab_size = len(word_to_ix)\n",
    "model = ehrStrat(len(word_to_ix), 10, 3, word_to_ix, ix_to_word, 20, 10)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.BCELoss() ##Binary Cross Entropy\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "##in order to compute the gradient with respect to both the input and the output:\n",
    "def mse_loss(input, target):\n",
    "    return torch.sum((input - target)**2) / input.data.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 10])\n",
      "tensor([[[-0.6643,  0.8762, -0.6143, -0.3364,  0.4487,  1.1991,  0.9402,\n",
      "           0.1418, -0.7355, -1.1137,  0.3531,  0.1092, -0.8300, -0.0348,\n",
      "          -0.8249, -0.0847, -0.6956,  0.5716,  1.2761, -0.0599,  2.2704,\n",
      "          -0.5221,  0.6090,  0.2705, -0.0831,  1.5431,  2.4835,  1.4663,\n",
      "           0.2456,  0.9603,  0.4076,  0.1794, -0.1108, -0.6419,  0.7720,\n",
      "          -1.3293,  0.0716, -0.1680, -0.0377,  1.3265,  0.4640, -1.3670,\n",
      "           1.6538, -0.7660,  0.3306,  0.3221, -0.1960,  0.1538,  1.7378,\n",
      "          -0.1399,  0.3531,  0.1092, -0.8300, -0.0348, -0.8249, -0.0847,\n",
      "          -0.6956,  0.5716,  1.2761, -0.0599,  0.5106, -1.2484, -2.3522],\n",
      "         [-1.8015,  0.6001,  0.3625, -1.1247, -0.8012,  0.0658, -0.7842,\n",
      "          -0.4731, -0.6165,  0.9291,  0.5663, -1.1135, -1.4214,  0.0254,\n",
      "           0.9612, -0.9145, -0.3315, -0.3892,  0.2691,  0.7364,  0.3031,\n",
      "          -0.9939, -1.0225, -0.5356, -1.0026, -0.3885,  0.3667,  0.2567,\n",
      "           1.4668, -1.5100,  1.2350,  0.6514, -0.3924, -1.1252, -1.1341,\n",
      "          -0.3043,  1.2951,  0.4045, -1.1325,  1.6848,  1.7534, -0.2136,\n",
      "           1.0141, -0.3762, -0.1613, -1.5292,  0.8499,  0.3531,  0.1092,\n",
      "          -0.8300, -0.0348, -0.8249, -0.0847, -0.6956,  0.5716,  1.2761,\n",
      "          -0.0599,  0.7597, -0.4111, -1.0252,  0.1063,  0.3241, -1.0442],\n",
      "         [-1.2195, -0.2473, -0.8376, -0.6516, -0.6643,  0.8762, -0.6143,\n",
      "          -0.3364,  0.4487,  1.1991,  0.9402,  0.1418, -0.7355, -1.1137,\n",
      "           0.3531,  0.1092, -0.8300, -0.0348, -0.8249, -0.0847, -0.6956,\n",
      "           0.5716,  1.2761, -0.0599,  0.7418, -0.2179, -0.9439,  2.5155,\n",
      "           1.2502, -0.1260,  1.0342, -0.4223, -1.4104, -0.4571,  2.2704,\n",
      "          -0.5221,  0.6090,  0.2705, -0.0831,  1.5431,  2.4835,  1.4663,\n",
      "           0.2456,  0.9603,  0.4045, -1.1325,  1.6848,  1.7534, -0.2136,\n",
      "           1.0141, -0.3762, -0.1613, -1.5292,  0.8499, -0.8120, -0.1382,\n",
      "          -0.4937,  0.0983,  0.9242,  1.7397,  0.4975,  1.4418, -0.5879],\n",
      "         [-0.2523, -0.7842,  0.6581, -1.4126,  0.7860,  0.6378, -0.1583,\n",
      "          -0.5737, -0.0805,  1.2495, -0.0329, -1.0825, -0.7958, -2.2722,\n",
      "           0.4497, -0.0645,  0.5491,  0.9415, -1.1076, -1.0945,  0.4982,\n",
      "           0.3167, -0.2466, -1.2256,  0.9536,  1.4802,  1.8793,  0.1429,\n",
      "          -0.1917,  1.1952,  1.2439,  1.4783, -1.3066, -0.2552,  1.0537,\n",
      "           0.3778, -0.8179, -0.9754, -0.3802,  0.4081,  0.7989,  0.3372,\n",
      "           1.5024, -0.4594,  0.3550,  0.6851,  0.7094, -1.5684,  0.7042,\n",
      "          -0.1549,  1.4300, -0.7194,  1.6528, -1.5983, -1.0723, -1.0053,\n",
      "          -1.0308,  1.5570, -0.3982,  0.0832,  1.2971,  1.2004, -1.1622],\n",
      "         [ 0.0679, -1.8878,  1.2321, -1.1179,  0.0353, -0.5332, -0.0523,\n",
      "          -1.2193, -0.1070,  0.9795, -1.3707,  1.5704, -1.5246,  0.1089,\n",
      "           0.4323, -0.1128,  0.4556,  0.0802, -1.2120,  0.3476,  0.7175,\n",
      "          -1.9522, -0.7741,  0.7388, -0.3626, -1.1360, -0.9224,  2.4009,\n",
      "           1.5260, -1.3885, -0.3155,  0.6981, -0.8971, -0.4850,  2.4556,\n",
      "          -0.9676,  0.2557,  0.5571, -0.0535,  1.2797,  1.3014,  0.1391,\n",
      "           0.6917, -0.6324, -0.1740,  2.2491,  0.1478,  1.1309,  1.5211,\n",
      "           0.8551, -0.6589, -0.7532, -0.3011, -0.8665, -0.4093, -0.4090,\n",
      "          -0.9636, -0.2451, -0.4719,  0.7055,  0.7847,  0.2792,  1.4398],\n",
      "         [-0.5782, -0.1899, -0.3079,  0.3549,  1.8362,  0.8509, -0.0989,\n",
      "          -0.5881, -0.8257,  0.1582,  1.6344, -0.0205, -0.2486, -0.6432,\n",
      "          -0.2436,  0.5106, -1.2484, -2.3522, -1.8015,  0.6001,  0.3625,\n",
      "          -1.1247, -0.8012,  0.0658, -0.7842,  0.7472,  0.3724, -1.0431,\n",
      "           0.8301,  0.5227, -0.0494, -0.3915, -0.4908,  1.2101, -0.0665,\n",
      "          -0.8783,  1.1854, -0.2524, -1.2541,  0.1201, -0.5667,  0.2078,\n",
      "           0.8732, -0.2631,  1.0717, -0.1813,  0.4950, -0.3118,  1.9746,\n",
      "          -0.9602,  0.4250, -0.3982,  0.9839, -0.4427,  0.1632, -1.0825,\n",
      "          -0.7958, -2.2722,  0.4497, -0.0645,  0.5491,  0.9415, -1.1076],\n",
      "         [-1.0945,  0.4982,  2.2704, -0.5221,  0.6090,  0.2705, -0.0831,\n",
      "           1.5431,  2.4835,  1.4663,  0.2456,  0.9603, -0.1426,  1.5920,\n",
      "           0.9777, -1.1146,  1.6777, -1.9168,  0.7366,  0.6924,  0.4357,\n",
      "          -0.2193, -0.7464,  1.4553,  1.8729,  0.2269,  0.7508, -1.6627,\n",
      "          -1.3533, -1.5326, -1.6845, -0.9632,  0.5562, -1.0184,  0.8732,\n",
      "          -0.6721,  1.0512,  1.2070,  0.0049,  0.6469,  1.0799,  1.1388,\n",
      "           0.4641, -1.6743,  1.3597, -0.2583,  0.7752,  0.9742, -2.2606,\n",
      "          -0.8033, -2.1909,  1.4745, -1.5302, -0.8770, -0.3673, -1.5813,\n",
      "          -0.0144, -1.0248, -0.8259, -1.4742,  0.1468,  0.5478,  2.5806],\n",
      "         [ 0.0708, -1.5510, -0.1071, -0.1509,  2.0093, -0.1652,  1.0300,\n",
      "           1.0419,  0.9766, -0.7047,  0.5142,  1.6197,  0.6511,  0.6184,\n",
      "          -0.4243, -0.1037, -0.5700,  1.3467, -0.4623, -0.9619, -0.0620,\n",
      "          -2.0566,  0.2831, -0.3389, -2.1012, -0.9524, -1.4284, -1.0456,\n",
      "          -0.2235, -3.0317, -1.5866,  1.1284,  1.0607, -1.4076, -0.1755,\n",
      "           0.2729, -1.0699, -1.9038, -0.1056, -0.6422,  0.6615, -0.2562,\n",
      "           1.9409, -0.1040,  1.9199,  1.4532,  0.4861, -0.6265,  0.5045,\n",
      "          -0.7352,  2.3386,  2.2228,  0.0035, -0.4726, -0.1754, -0.8082,\n",
      "          -0.6073, -0.6494, -2.5295,  0.2101,  0.0469,  0.8020,  1.6065],\n",
      "         [ 2.0640,  1.1106, -0.2836,  0.5455,  0.6961, -0.5950, -0.8264,\n",
      "           0.3920,  1.1767, -0.9511, -0.2790,  1.0030, -0.1870,  1.0811,\n",
      "          -1.1570,  1.3203, -0.9756,  0.8343, -0.2583, -0.4141,  0.5285,\n",
      "          -1.7898,  1.6555,  0.5660,  1.2994, -1.3186,  0.3640, -0.6328,\n",
      "          -0.2477,  0.8135, -1.1901, -0.5596, -0.2788,  0.4101,  0.9433,\n",
      "          -0.9875, -0.6662,  0.0238,  1.8614, -1.4306,  0.0302, -1.0261,\n",
      "          -1.2491,  0.0496,  2.4570, -1.5251,  0.7811,  0.8026, -0.4281,\n",
      "           0.5410, -0.2695,  0.4808, -0.1938, -0.1545, -0.1549,  0.7721,\n",
      "           0.4117, -0.9223,  0.3738, -0.6197,  1.2937,  2.6140,  1.4794],\n",
      "         [ 0.7756, -0.2573, -0.0684, -0.6662,  0.0238,  1.8614, -1.4306,\n",
      "           0.0302, -1.0261, -1.2491,  0.0496,  2.4570, -1.5251, -0.1813,\n",
      "           0.4950, -0.3118,  1.9746, -0.9602,  0.4250, -0.3982,  0.9839,\n",
      "          -0.4427,  0.1632,  1.2169,  1.0647,  1.0061, -1.6756,  0.2760,\n",
      "           0.9381, -0.4273, -1.3782, -0.5243, -0.3556, -0.7842,  0.6581,\n",
      "          -1.4126,  0.7860,  0.6378, -0.1583, -0.5737, -0.0805,  1.2495,\n",
      "          -0.0329, -0.1813,  0.4950, -0.3118,  1.9746, -0.9602,  0.4250,\n",
      "          -0.3982,  0.9839, -0.4427,  0.1632,  1.2005, -1.5967,  0.6365,\n",
      "          -2.4546, -0.6142, -0.1380, -0.4254, -2.2042, -1.2471,  0.7231]]]) torch.Size([1, 10, 63])\n",
      "tensor([[[ 8.4955e-02,  1.8686e-02,  1.6027e-01, -2.3079e-01,  4.1942e-01,\n",
      "           2.6366e-01, -4.2620e-01, -6.5891e-02, -7.4064e-01, -7.8563e-02,\n",
      "           2.4418e-01, -1.0401e-01, -1.0045e+00, -3.1924e-01,  5.4813e-01,\n",
      "           1.6896e-01,  6.7384e-01, -2.3410e-01, -1.0076e-01,  2.7647e-01,\n",
      "           2.7801e-01, -5.9949e-05, -3.6422e-01,  9.1459e-01, -2.8814e-01,\n",
      "           2.6009e-01, -9.4500e-02,  6.4691e-01,  5.6729e-01, -6.7252e-01,\n",
      "           1.9650e-01,  2.3517e-01, -1.8595e-01,  8.5430e-01, -1.8098e-01,\n",
      "          -8.3791e-01,  2.8836e-01,  3.6032e-02, -9.7093e-01,  4.6807e-01,\n",
      "          -1.0025e-01, -3.4355e-01, -1.6618e-01,  3.8241e-01, -1.5527e-01,\n",
      "           1.2158e+00, -5.7037e-02, -8.4061e-01,  1.0669e+00, -1.2578e-01,\n",
      "           6.1694e-01, -4.0175e-01,  9.2981e-01, -6.4989e-01, -7.1178e-01,\n",
      "           5.6775e-02, -5.7453e-01,  7.0457e-01,  5.6938e-02, -1.9115e-01,\n",
      "          -4.7919e-03,  6.5173e-01,  3.1778e-02],\n",
      "         [ 9.2416e-01, -7.8326e-01, -1.2076e-01, -3.0358e-02, -7.6659e-01,\n",
      "           3.7604e-01,  1.8698e-01, -1.3634e-01, -5.1157e-02, -3.6284e-01,\n",
      "          -1.3965e+00,  3.6343e-01,  1.5702e-01, -9.9084e-03, -2.6660e-01,\n",
      "          -8.8226e-01,  5.0764e-01, -1.7880e-01,  9.1396e-01,  1.1777e-01,\n",
      "           1.0092e-01,  1.2889e+00, -8.7025e-01, -2.7010e-01,  6.3729e-01,\n",
      "           6.5410e-02,  1.1271e+00,  3.1844e-01,  4.4567e-01,  1.7878e+00,\n",
      "          -8.1600e-01, -6.2954e-01,  1.2335e+00, -2.5138e-01, -6.5916e-01,\n",
      "           4.9649e-01, -1.1897e-01,  4.5696e-01,  5.7121e-01, -8.0035e-01,\n",
      "          -5.8272e-01,  4.5938e-01, -4.0122e-01,  5.7154e-01, -1.3776e+00,\n",
      "          -1.1593e-01,  4.8284e-01,  8.8626e-01, -1.1476e+00,  1.1061e+00,\n",
      "          -1.6503e+00,  8.6228e-01, -1.8204e-01,  1.0214e+00,  3.9430e-01,\n",
      "           9.4240e-02,  3.8579e-01,  2.1511e-02,  5.6981e-01, -2.7004e-01,\n",
      "          -5.2410e-01, -2.4781e+00,  1.5066e-01],\n",
      "         [ 4.6501e-01,  4.2254e-01, -8.8503e-02,  2.2254e-01, -6.2752e-01,\n",
      "          -5.7847e-03,  6.6477e-01,  9.2627e-01, -6.2389e-02, -2.3352e-01,\n",
      "          -1.0826e-01,  5.3554e-01,  1.5145e+00,  2.9737e-01, -5.1127e-02,\n",
      "           4.5611e-01, -5.0661e-02,  1.2353e+00,  4.1988e-01,  1.3411e-01,\n",
      "           4.4150e-01, -1.5197e-01,  1.5535e-01,  2.2617e-01,  5.0438e-01,\n",
      "          -3.2604e-01, -1.0092e+00, -2.2589e+00,  1.4037e-02, -7.2941e-01,\n",
      "          -1.4589e+00,  7.4739e-02, -2.0283e-01, -5.6517e-01, -8.1534e-01,\n",
      "           3.4058e-01, -1.4343e-01,  4.1986e-01,  2.7097e-02, -6.4328e-01,\n",
      "           3.1505e-02,  3.3222e-02, -4.1024e-02, -8.7675e-03,  4.5291e-02,\n",
      "          -1.0805e+00,  7.2999e-01, -1.0006e+00, -3.4938e-01, -6.8271e-01,\n",
      "           9.6390e-01, -7.0619e-01,  5.4108e-01, -4.6861e-01,  3.0532e-01,\n",
      "           4.6066e-01, -2.2423e-01, -1.0442e+00, -4.3314e-01, -1.3486e+00,\n",
      "          -5.4723e-01, -1.3499e-01, -4.2150e-01],\n",
      "         [ 4.8022e-02,  7.6026e-01, -7.0019e-01,  3.3975e-01, -3.5189e-01,\n",
      "           2.8721e-01, -5.2829e-02,  1.4846e-01, -3.5740e-01, -1.1153e+00,\n",
      "          -1.3552e-01,  3.4598e-01, -1.3119e-01,  1.2534e-01, -8.1453e-01,\n",
      "           1.7162e-01, -8.6090e-01, -4.9224e-01,  7.3145e-02, -2.0426e-02,\n",
      "          -3.8339e-01, -5.4814e-01,  6.6862e-01, -6.6889e-01, -6.1674e-01,\n",
      "          -2.5560e-01, -7.9482e-01, -1.2517e-02, -1.3501e+00,  4.2916e-01,\n",
      "           2.5584e-01, -8.3964e-02, -6.6100e-01,  2.6644e-02,  1.2244e-01,\n",
      "          -1.3756e+00,  2.9994e-02, -2.0681e-01, -4.9600e-04, -3.9115e-01,\n",
      "          -8.6931e-01, -3.7325e-01, -1.0085e+00,  3.9448e-01,  1.5539e-01,\n",
      "          -1.1721e+00, -5.0306e-01, -5.2504e-01, -4.4765e-01, -1.1749e-01,\n",
      "           1.9477e-01, -2.1227e-01, -7.6622e-01,  1.1425e+00, -2.3866e-01,\n",
      "           8.4728e-01, -1.1746e-01, -9.7195e-01,  4.0525e-01,  2.5840e-01,\n",
      "          -3.4352e-01, -1.6505e-01, -1.3475e+00],\n",
      "         [-5.8733e-01, -7.3536e-03,  2.6223e-01,  6.7952e-01,  5.5270e-01,\n",
      "           3.1759e-01,  9.4875e-02, -5.4449e-02, -9.4307e-02,  6.4647e-01,\n",
      "           9.0300e-01,  3.4843e-02, -1.0259e+00,  2.3782e-01, -1.0673e-01,\n",
      "           3.9013e-01, -4.1079e-01, -4.7226e-01, -2.9394e-01, -2.9658e-01,\n",
      "           3.3429e-01, -2.9604e-01, -2.2893e-01, -5.3570e-01, -2.3746e-01,\n",
      "           2.9334e-01, -3.0833e-01,  3.5507e-01, -1.2502e+00, -7.2021e-01,\n",
      "           5.6455e-01,  5.7432e-01, -3.2398e-02, -1.8219e-01, -3.1515e-01,\n",
      "          -4.3661e-02,  2.1004e-01, -5.4248e-01, -5.2342e-01, -2.0553e-02,\n",
      "           4.2391e-01,  3.5135e-01,  2.7113e-01,  1.8259e-01, -3.5183e-01,\n",
      "           7.6198e-01, -8.7960e-01, -8.1991e-01, -3.3678e-01, -3.8448e-01,\n",
      "           5.0234e-01, -1.1933e-01,  4.8654e-01,  8.8350e-02, -9.2898e-01,\n",
      "          -1.6075e-01, -7.7939e-01, -4.9156e-02, -1.7684e-01, -6.8160e-01,\n",
      "          -8.0120e-01,  2.5547e-01,  5.8311e-03],\n",
      "         [ 6.0337e-01, -4.6179e-01, -6.4153e-02,  3.7173e-01,  8.9722e-02,\n",
      "          -5.2737e-01, -1.5950e-01, -5.8572e-01, -5.5390e-01,  6.7051e-01,\n",
      "           4.5705e-01, -4.8159e-02, -1.8606e-01, -1.7369e-01, -4.1773e-01,\n",
      "           6.8700e-01, -1.1898e+00,  1.0787e+00, -3.2792e-02, -7.0361e-02,\n",
      "           4.3920e-01, -2.6469e-01,  1.2209e+00,  1.2584e-01,  1.0591e+00,\n",
      "           2.0133e-01, -1.0322e+00,  4.6826e-01,  2.7636e-01, -4.0917e-01,\n",
      "          -6.3355e-01,  1.4171e-01, -5.0707e-01, -5.0550e-01,  2.6080e-01,\n",
      "           5.8980e-01,  1.2823e-01, -2.2480e-01,  5.8928e-01, -4.6396e-01,\n",
      "           4.8799e-01,  1.1982e-01, -4.1324e-01, -3.4102e-01, -5.9093e-01,\n",
      "          -3.1484e-01, -2.7173e-01, -1.3222e-02, -1.5373e-01, -4.4376e-01,\n",
      "           1.6033e-01, -1.3765e+00,  5.7241e-02, -2.3076e-01, -6.7519e-01,\n",
      "          -1.6633e-01, -7.8304e-01,  7.0405e-01,  2.2184e-01, -3.8236e-01,\n",
      "          -1.0324e+00, -1.5490e-01,  1.4268e-01],\n",
      "         [-2.0008e-02,  4.6725e-01, -6.0233e-01,  4.8172e-01,  6.7767e-01,\n",
      "          -3.3666e-01,  2.6776e-01,  2.5704e-01,  1.6545e+00,  8.1201e-01,\n",
      "          -5.0579e-01, -8.7761e-01,  8.1459e-01,  6.5741e-01, -4.7111e-01,\n",
      "           3.3718e-02, -5.8984e-01,  1.3196e-01, -3.7978e-02,  1.4080e-01,\n",
      "          -1.1535e+00,  1.3863e-01, -1.9872e-01,  1.5730e-01,  9.7698e-01,\n",
      "           2.8768e-01,  1.7293e-01, -8.1741e-01, -1.5884e+00, -2.5773e-01,\n",
      "          -4.3307e-01, -1.2837e+00, -1.4174e-01,  3.6106e-01, -9.9489e-01,\n",
      "           1.2510e+00, -7.8629e-01, -1.1103e+00,  7.4534e-01,  2.0679e-02,\n",
      "          -3.8598e-01,  7.2470e-01, -7.7974e-01,  2.4072e-01, -7.4920e-02,\n",
      "           9.4832e-01, -6.3035e-01,  5.8456e-01, -1.7596e+00, -1.0236e-01,\n",
      "          -7.8696e-01,  9.6220e-01, -1.0156e-01, -7.4105e-01, -1.0733e-01,\n",
      "          -1.5367e+00,  4.1073e-01, -5.3619e-01, -1.0384e+00, -4.1709e-01,\n",
      "          -7.6158e-02, -2.2988e-01,  8.8470e-01],\n",
      "         [-1.5233e-01,  1.7542e-01, -7.6212e-01, -1.9822e-01,  2.7206e-01,\n",
      "           5.3574e-01, -7.3012e-01, -2.4121e-01,  1.0566e+00,  4.4806e-01,\n",
      "          -1.1585e+00, -1.1306e-01, -1.5412e-01,  1.0743e+00,  2.6395e-01,\n",
      "          -3.0075e-01,  1.1438e-01, -2.6719e-01, -3.0992e-01,  4.1237e-01,\n",
      "          -9.5850e-02, -6.7263e-01, -6.5994e-01,  1.2515e-01,  4.2239e-01,\n",
      "           1.0230e-01, -7.1531e-02,  7.0222e-01, -8.5077e-01, -1.4706e-01,\n",
      "          -2.9736e-01, -1.6462e+00, -7.1087e-01,  8.9227e-01,  3.3643e-01,\n",
      "          -2.8332e-01,  2.2979e-01, -3.8232e-01,  8.1603e-01,  9.4074e-01,\n",
      "          -7.0218e-01,  1.8069e-01, -6.4317e-01, -5.6494e-01, -3.2428e-01,\n",
      "           8.1758e-01,  1.7163e-01,  5.7700e-01,  4.7848e-02, -2.9057e-01,\n",
      "          -1.2742e+00, -3.0647e-01, -6.8099e-02, -3.1309e-02, -1.6497e-01,\n",
      "          -1.7459e-02,  1.0478e-01,  1.4038e-01, -6.8530e-01,  1.5661e-01,\n",
      "          -7.1751e-01, -1.1888e+00,  4.3850e-01],\n",
      "         [ 2.9450e-01, -3.7193e-01,  6.6747e-01,  2.6067e-01,  1.6117e-01,\n",
      "          -1.1097e-01,  2.1647e-01,  1.5003e-01,  1.0544e-01,  2.4237e-02,\n",
      "           1.0310e-01,  5.0836e-01, -9.5849e-02, -3.0799e-02,  2.2021e-01,\n",
      "           5.5575e-01,  1.0673e-01,  9.8198e-01, -1.1859e+00,  4.3289e-01,\n",
      "           5.3406e-01, -5.6998e-01,  4.7930e-02, -3.0512e-01,  1.3788e-01,\n",
      "           1.9244e-01, -6.3348e-01, -5.9328e-01, -1.2305e-01, -7.7517e-01,\n",
      "          -2.2060e-01,  6.5391e-01, -2.6221e-01, -1.8565e-01,  8.4775e-01,\n",
      "          -1.1531e+00,  8.7079e-02,  7.3651e-01,  2.2595e-01, -4.3775e-01,\n",
      "           2.6700e-02, -2.1031e-01, -1.0214e-01, -3.8966e-01,  4.7625e-01,\n",
      "          -6.4680e-01, -2.7396e-01, -1.1318e-01, -1.5002e-01, -2.7292e-01,\n",
      "          -1.2621e-01, -3.0742e-01, -6.8350e-01, -8.8835e-02, -2.2264e-01,\n",
      "           5.3434e-01,  7.2046e-01,  1.0223e-01, -8.2766e-01,  1.7260e-01,\n",
      "          -3.9864e-01,  6.2795e-01,  5.5239e-01],\n",
      "         [-7.2477e-01,  5.8217e-01,  6.8215e-02,  6.0180e-01,  2.9792e-02,\n",
      "           7.8594e-01, -2.8072e-01, -5.1797e-01, -1.8556e-01,  7.1850e-01,\n",
      "           7.2321e-01, -8.4793e-01, -1.9439e-01, -5.7544e-01,  1.1476e-02,\n",
      "          -2.0779e-01, -9.6605e-01,  9.2265e-02, -4.3636e-01,  2.4100e-01,\n",
      "           3.3250e-02, -4.9645e-01, -2.4961e-01, -1.5612e+00,  2.0529e-01,\n",
      "           7.6444e-01,  6.5949e-01,  1.2865e+00, -8.9485e-01,  1.3919e-01,\n",
      "           1.1293e+00,  3.5856e-01, -9.4381e-01, -3.8776e-01,  2.7639e-01,\n",
      "           1.8620e-01, -2.4151e-01, -2.6119e-01,  7.7287e-01,  8.1966e-01,\n",
      "           3.6502e-01,  3.3109e-01, -2.2161e-01, -2.1898e-01,  2.2381e-01,\n",
      "          -4.5185e-01,  1.0371e-01,  6.3334e-01,  2.7316e-01, -1.1993e-01,\n",
      "           9.7867e-02, -1.2495e+00, -5.9809e-01, -6.2483e-02, -8.6443e-01,\n",
      "           2.4613e-01, -5.0099e-01,  2.8702e-01, -3.0477e-01,  3.1245e-01,\n",
      "          -2.3586e-01,  8.7758e-01, -5.2941e-01]]]) torch.Size([1, 10, 63])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-8b72d12d3c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#==========forward=============\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpre_ae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#pre_ae = pre_ae.detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/users/isotta/multMyeloma/bin_pytorch/dl4ehr/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-020ad06d3b48>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkmaxPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_max1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "for epoc in range(50):\n",
    "    total_loss = 0\n",
    "    for sequence in data:\n",
    "        sequence = torch.tensor(sequence)\n",
    "        #==========forward=============\n",
    "        pre_ae, output = model(sequence)\n",
    "        #pre_ae = pre_ae.detach()\n",
    "        print(output)\n",
    "        print(pre_ae) ##is not being optimized!!\n",
    "        #loss = loss_function(output, pre_ae)\n",
    "        #print(loss)\n",
    "        MSE_loss = mse_loss(pre_ae, output)\n",
    "        print(MSE_loss)\n",
    "        #==========backward============\n",
    "        optimizer.zero_grad()\n",
    "        MSE_loss.backward()\n",
    "        optimizer.step\n",
    "        \n",
    "        total_loss += MSE_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(H[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f8132f89780>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-a7e6e71316ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'd'"
     ]
    }
   ],
   "source": [
    "m = ae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class persona(nn.Module):\n",
    "    def __init__(self, nome, age):\n",
    "        super(persona, self).__init__()\n",
    "        self.nome = nome\n",
    "        self.age = age\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        print(self.nome)\n",
    "        print(self.prova(\"benegrazie\", x))\n",
    "        ciao = lavoro(3,4)\n",
    "        print(ciao.vai())\n",
    "        print()\n",
    "        \n",
    "    def prova(self,cosa,x):\n",
    "        print(x)\n",
    "        #print(\"benegrazie\")\n",
    "        return(cosa)\n",
    "    \n",
    "class lavoro():\n",
    "    def __init__(self, anni, tipo):\n",
    "        self.anni = anni\n",
    "        self.tipo = tipo\n",
    "        \n",
    "    def vai(self):\n",
    "        return(\"macche\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao = lavoro(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macche'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciao.vai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "matteo = persona(nome=\"matteo\", age=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boh\n",
      "matteo\n",
      "boh\n",
      "benegrazie\n",
      "macche\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matteo('boh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matteo'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matteo.nome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matteo.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (list, list), but expected one of:\n * (torch.device device)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m, \u001b[31;1mlist\u001b[0m)\n * (torch.Storage storage)\n * (Tensor other)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m, \u001b[31;1mlist\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-b8fa048c4bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (list, list), but expected one of:\n * (torch.device device)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m, \u001b[31;1mlist\u001b[0m)\n * (torch.Storage storage)\n * (Tensor other)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mlist\u001b[0m, \u001b[31;1mlist\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3,4,5,6], [2,3,4,5,6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
       "        [ 2.,  3.,  4.,  5.,  6.,  7.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  6.],\n",
       "         [ 6.,  7.]]), tensor([[ 4,  5],\n",
       "         [ 4,  5]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.topk(2, sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6754,  0.5990],\n",
      "         [ 0.0938,  0.9188],\n",
      "         [ 0.4129,  0.1722]],\n",
      "\n",
      "        [[ 0.6449,  0.0940],\n",
      "         [ 0.4869,  0.6581],\n",
      "         [ 0.3957,  0.1160]]])\n"
     ]
    }
   ],
   "source": [
    "prova = torch.rand(2,3,2)\n",
    "print(prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6754],\n",
       "         [ 0.9188],\n",
       "         [ 0.4129]],\n",
       "\n",
       "        [[ 0.6449],\n",
       "         [ 0.6581],\n",
       "         [ 0.3957]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova.topk(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVE\n",
    "\n",
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supponiamo di avere tre pazienti con EHRs di lunghezze diverse \n",
    "#vogliamo applicare CBOW considerando il contesto K (user-defined) separatamente per ogni \"sentence\",\n",
    "#cioe' separatamente per ogni paziente\n",
    "#Creiamo one array con different arrays storing the tokens of the medical terms\n",
    "# one array for each patient\n",
    "P1 = \"A wiki is run using wiki software, otherwise known as a wiki engine.\\\n",
    "         A wiki engine is a type of content management system, but it differs\\\n",
    "         from most other such systems, including blog software, in that the\\\n",
    "         content is created without any defined owner or leader, and wikis have\\\n",
    "         little implicit structure, allowing structure to emerge according to the\\\n",
    "         needs of the users.\"\n",
    "\n",
    "P2 = \"The online encyclopedia project Wikipedia is by far the most popular wiki-based\\\n",
    "         website, and is one of the most widely viewed sites of any kind in the world,\\\n",
    "         having been ranked in the top ten since 2007.\"\n",
    "\n",
    "P3 = \"Wikipedia is not a single wiki but rather a collection of hundreds of wikis,\\\n",
    "         one for each language. There are tens of thousands of other wikis in use, both\\\n",
    "         public and private, including wikis functioning as knowledge management resources,\\\n",
    "         notetaking tools, community websites and intranets. The English-language Wikipedia\\\n",
    "         has the largest collection of articles; as of September 2016, it had over five\\\n",
    "         million articles.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ARRAY with tokens from patients\n",
    "H = [P1.split(), P2.split(), P3.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fun1: creiamo il nostro dictionary (associamo univocamente un token a un intero)\n",
    "##Input: array of sentences\n",
    "def create_dict(array_sentences): \n",
    "    word_to_ix = {}\n",
    "\n",
    "    for _, j in enumerate(array_sentences):\n",
    "        for word in j:\n",
    "            if word not in word_to_ix:\n",
    "                word_to_ix[word] = len(word_to_ix)\n",
    "    return word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = create_dict(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fun2: now we want to create the context on which to train the CBOW, \n",
    "##considering separately the sentences (i.e. the patients)        \n",
    "def create_context(dim_context, array_sentences):\n",
    "    data = []\n",
    "\n",
    "    for sentence in array_sentences:\n",
    "        for i in range(dim_context, len(sentence) - dim_context):\n",
    "            context = [sentence[j] for j in range(i-dim_context, i-1)] + [sentence[j] for j in range(i + 1, i + dim_context)]\n",
    "            target = sentence[i]\n",
    "            data.append((context, target))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_context(4, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fun3: this function will translate context into a tensor of integers based on the dictionary\n",
    "##We will use this function during the CBOW() training\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context] ##word_to_ix is the dictionary with words in text and numbers\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CBOW class for word embedding\n",
    "class CBOW(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        self.activation2 = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = sum(self.embeddings(inputs)).view((1, -1))\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation2(out)\n",
    "        return out\n",
    "    \n",
    "    def get_word_embedding(self, word):\n",
    "        word = torch.LongTensor([word_to_ix[word]])\n",
    "        return self.embeddings(word).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRAINING\n",
    "EMBEDDING_DIM = 10\n",
    "vocab_size = len(word_to_ix)\n",
    "model = CBOW(vocab_size, EMBEDDING_DIM)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(50):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        context_vector = make_context_vector(context, word_to_ix)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_vector)\n",
    "        loss = loss_function(log_probs, torch.LongTensor([word_to_ix[target]]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fun4: return the array of the embedding tensors, one for each patien\n",
    "##dimensions of the tensors vary w.r.t patients, although the embedding dimension doesn't vary\n",
    "##tensor([T_i,d]), where T_i depends on the length of the EHR for patient i and d is the user-defined embedding dimension\n",
    "def pat_embedding(array_sentences, emb_dim, model):\n",
    "    mat_all = []\n",
    "\n",
    "    for sentence in array_sentences:\n",
    "        emb = torch.empty(len(sentence), emb_dim)\n",
    "        for med_term in sentence:\n",
    "            emb = torch.cat((emb, model.get_word_embedding(med_term).detach()),0)\n",
    "        mat_all += [emb]\n",
    "\n",
    "    return mat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_all = pat_embedding(H, EMBEDDING_DIM, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find word 13\n"
     ]
    }
   ],
   "source": [
    "##TEST\n",
    "context = \"tens of of other wikis\".split()\n",
    "context_vector = make_context_vector(context, word_to_ix)\n",
    "pred = model(context_vector).data.numpy()\n",
    "\n",
    "index = 0\n",
    "for i in range(pred.shape[1]):\n",
    "    if pred[0, i] > pred[0, index]:\n",
    "        index = i\n",
    "print(\"find word {0:d}\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('wikis,', 78), ('articles;', 101), ('differs', 19), ('world,', 65), ('language.', 81), ('management', 15), ('not', 73), ('such', 23), ('and', 37), ('largest', 100), ('little', 40), ('is', 2), ('ranked', 68), ('otherwise', 6), ('most', 21), ('A', 0), ('a', 9), ('by', 55), ('public', 88), ('any', 32), ('including', 25), ('2016,', 103), ('the', 29), ('websites', 96), ('structure,', 42), ('structure', 44), ('collection', 76), ('notetaking', 93), ('have', 39), ('had', 104), ('website,', 59), ('million', 107), ('implicit', 41), ('to', 45), ('been', 67), ('wiki', 1), ('system,', 16), ('it', 18), ('systems,', 24), ('thousands', 85), ('using', 4), ('leader,', 36), ('private,', 89), ('single', 74), ('but', 17), ('from', 20), ('for', 79), ('online', 51), ('as', 8), ('created', 30), ('intranets.', 97), ('English-language', 98), ('use,', 86), ('engine', 11), ('hundreds', 77), ('since', 71), ('of', 13), ('over', 105), ('or', 35), ('allowing', 43), ('type', 12), ('owner', 34), ('kind', 64), ('content', 14), ('There', 82), ('users.', 49), ('articles.', 108), ('needs', 48), ('defined', 33), ('has', 99), ('far', 56), ('tens', 84), ('top', 69), ('blog', 26), ('wikis', 38), ('without', 31), ('knowledge', 91), ('known', 7), ('Wikipedia', 54), ('other', 22), ('emerge', 46), ('The', 50), ('run', 3), ('in', 27), ('one', 60), ('wiki-based', 58), ('engine.', 10), ('rather', 75), ('are', 83), ('project', 53), ('resources,', 92), ('viewed', 62), ('tools,', 94), ('community', 95), ('having', 66), ('that', 28), ('software,', 5), ('2007.', 72), ('sites', 63), ('five', 106), ('popular', 57), ('both', 87), ('each', 80), ('September', 102), ('encyclopedia', 52), ('ten', 70), ('widely', 61), ('according', 47), ('functioning', 90)])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix.items()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
