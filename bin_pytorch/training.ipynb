{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "We create two dictionaries, the first stores `{mrn:[patient_sequence]}`, the second is of the form `{'train':[mrns], 'test':[mrns]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from collections import OrderedDict, defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.expanduser(\"~/data1/multMyeloma/data/\")\n",
    "EHR_FILENAME = \"MMehr_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read the dictionaries of medical terms\n",
    "with open(os.path.join(DATA_PATH, 'rxnorm_to_ix.csv'), 'r') as infile:\n",
    "    file = csv.reader(infile, delimiter=',')\n",
    "    rxnorm_to_ix = {}\n",
    "    for el in file:\n",
    "        rxnorm_to_ix[el[0]] = int(el[1])\n",
    "        \n",
    "with open(os.path.join(DATA_PATH, 'ix_to_rxnorm.csv'), 'r') as infile:\n",
    "    file = csv.reader(infile, delimiter=',')\n",
    "    ix_to_rxnorm = {}\n",
    "    for el in file:\n",
    "        ix_to_rxnorm[int(el[0])] = el[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read the data\n",
    "with open(os.path.join(DATA_PATH, 'mrn_unique.csv'), 'r', newline='') as f1:\n",
    "    rows = csv.reader(f1, delimiter=\",\", quotechar='\"')\n",
    "    mrn_unique = [int(row[0]) for row in rows]\n",
    "\n",
    "with open(os.path.join(DATA_PATH, 'patient_sequences.csv'), 'r', newline='') as f2:\n",
    "    rows = csv.reader(f2, delimiter=',', quotechar='\"')\n",
    "    patient_sequences = []\n",
    "    for row in rows:\n",
    "        patient_sequences += [[int(row[i]) for i in range(len(row))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehrs = {}\n",
    "\n",
    "for idp in range(len(mrn_unique)):\n",
    "    ehrs[mrn_unique[idp]] = patient_sequences[idp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "traintest = {'train':[], 'test':[]}\n",
    "test_idx = random.sample(range(len(mrn_unique)), int(len(mrn_unique) * 0.2))\n",
    "\n",
    "for i in range(len(mrn_unique)):\n",
    "    if i in test_idx:\n",
    "        traintest['test'].append(mrn_unique[i])\n",
    "    else:\n",
    "        traintest['train'].append(mrn_unique[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMdata(Dataset):\n",
    "    def __init__(self, list_mrn, dic_seq):\n",
    "        self.list_mrn = list_mrn\n",
    "        self.dic_seq = dic_seq\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        mrn_idx = self.list_mrn[index]\n",
    "        sequence = self.dic_seq[mrn_idx]\n",
    "        #sequence = torch.tensor(sequence)\n",
    "        \n",
    "        #print(type(sequence), type(mrn_idx))\n",
    "        return sequence, mrn_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_mrn)\n",
    "    \n",
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    data = torch.tensor(data)\n",
    "    target = [item[1] for item in batch]\n",
    "    target = torch.LongTensor(target)\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import the model class ehrModel()\n",
    "%run ehrStratModel.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, each worker will have its PyTorch seed set to base_seed + worker_id, where base_seed is a long generated by main process using its RNG. \n",
    "params = {'batch_size': 5,\n",
    "          'shuffle': True}\n",
    "max_epochs = 10\n",
    "\n",
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "random.seed(12)\n",
    "\n",
    "training_set, test_set = MMdata(traintest['train'], ehrs), MMdata(traintest['test'], ehrs)\n",
    "training_generator = data.DataLoader(training_set, **params, collate_fn=my_collate)\n",
    "test_generator = data.DataLoader(test_set, **params, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = next(iter(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14081"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rxnorm_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an input of size $(N, 1, T)$, where $N$ is the _batch size_, and $T=65979$ is the length of the ehr sequence for all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ehrModel(\n",
      "  (embedding): Embedding(14081, 100, padding_idx=0)\n",
      "  (cnn): Conv2d(1, 1, kernel_size=(5, 100), stride=(1, 1), padding=(2, 0))\n",
      "  (cnn2): Conv1d(1, 1, kernel_size=(5, 1), stride=(1,), padding=(2, 0))\n",
      ")\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.4080,  0.0281],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.5011,  0.0000]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n",
      "tensor([[     0,      0,      0,  ...,   1363,   1325,   1342],\n",
      "        [     0,      0,      0,  ...,     26,    132,    281]], device='cuda:0')\n",
      "CE loss: 65919.9140625\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000,  0.0000,  0.0000,  ...,  0.0638,  0.0000,  0.9969],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0860,  0.0000,  0.7015]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n",
      "tensor([[    0,     0,     0,  ...,   132,   281,   375],\n",
      "        [    0,     0,     0,  ...,   407,    44,   406]], device='cuda:0')\n",
      "CE loss: 65808.8671875\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000,  0.0000,  0.0402,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.3841,  ...,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n",
      "tensor([[     0,      0,      0,  ...,     53,    703,    591],\n",
      "        [     0,      0,      0,  ...,     12,     12,     44]], device='cuda:0')\n",
      "CE loss: 65853.140625\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 1.0909,  0.0000,  0.5123,  ...,  1.7138,  1.2037,  2.2680],\n",
      "        [ 1.0853,  0.0000,  0.5339,  ...,  1.7239,  1.2068,  2.3284]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n",
      "tensor([[    0,     0,     0,  ...,   128,    44,    44],\n",
      "        [    0,     0,     0,  ...,   128,   128,   108]], device='cuda:0')\n",
      "CE loss: 65827.84375\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.6716,  0.0000,  3.7607,  ...,  0.0000,  0.7689,  0.4907],\n",
      "        [ 0.2925,  0.0000,  3.0991,  ...,  0.0000,  0.8104,  0.4425]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n",
      "tensor([[    0,     0,     0,  ...,   116,   114,   115],\n",
      "        [    0,     0,     0,  ...,   114,   116,   115]], device='cuda:0')\n",
      "CE loss: 65664.6640625\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000,  0.0000,  2.7336,  ...,  1.7931,  0.8467,  0.0000],\n",
      "        [ 0.0000,  0.0000,  2.5913,  ...,  2.0068,  1.0583,  0.0000]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n",
      "tensor([[    0,     0,     0,  ...,   108,   108,   108],\n",
      "        [    0,     0,     0,  ...,   185,  1671,  1750]], device='cuda:0')\n",
      "CE loss: 65889.703125\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 0.0000,  0.0000,  0.3412,  ...,  0.0000,  2.4283,  1.5419],\n",
      "        [ 0.0000,  0.0000,  0.1242,  ...,  0.0000,  1.7623,  1.1820]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n",
      "tensor([[     0,      0,      0,  ...,    128,    128,    128],\n",
      "        [     0,      0,      0,  ...,    279,    205,    208]], device='cuda:0')\n",
      "CE loss: 65899.015625\n",
      "Shape original mat: torch.Size([5, 65979])\n",
      "Size embedding matrix: torch.Size([5, 65979, 100])\n",
      "Embedding reshaping dimension: torch.Size([5, 1, 65979, 100])\n",
      "Output cnn: torch.Size([5, 1, 65979, 1])\n",
      "Dimension after first maxpooling: torch.Size([5, 1, 13196, 1])\n",
      "After Convolution dimension: torch.Size([5, 1, 2640, 1])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "Output from CNN: torch.Size([5, 2640])\n",
      "Reshaping dimension: torch.Size([5, 2640])\n",
      "AE input vector: 2640\n",
      "65979\n",
      "AE output dimension: torch.Size([5, 65979])\n",
      "Dimension of the encoded vector: torch.Size([5, 660])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 1.7439,  0.0000,  0.0000,  ...,  0.6004,  0.0000,  0.5009],\n",
      "        [ 1.8103,  0.0000,  0.0000,  ...,  0.6299,  0.0000,  0.5521]], device='cuda:0')\n",
      "torch.Size([5, 65979])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8f7b491febfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mmlml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLabelMarginLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/users/isotta/multMyeloma/bin_pytorch/dl4ehr/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/users/isotta/multMyeloma/bin_pytorch/dl4ehr/lib/python3.5/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', dtype='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_number_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSCALE_FORMAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/users/isotta/multMyeloma/bin_pytorch/dl4ehr/lib/python3.5/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mint_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# TODO: use fmod?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mint_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/users/isotta/multMyeloma/bin_pytorch/dl4ehr/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration over a 0-d tensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab_size = len(rxnorm_to_ix)\n",
    "embedding_dim = 100\n",
    "kernel_size = 5\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = ehrModel(vocab_size, embedding_dim, kernel_size)\n",
    "#model = torch.nn.DataParallel(model, device_ids=[0, 2, 3])\n",
    "print(model.cuda())\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "##in order to compute the gradient with respect to both the input and the output:\n",
    "def mse_loss(input, target):\n",
    "    return torch.sum((input - target)**2) / input.data.nelement()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for batch, mrns in training_generator:\n",
    "        batch = batch.to(device, torch.long)\n",
    "        #print(\"vect {0:1d}\".format(i))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        input_mat, out, encoded_vect = model(batch)\n",
    "        print(out[1:3])\n",
    "        print(out.shape)\n",
    "        print(batch[1:3])\n",
    "        mlml = nn.MultiLabelMarginLoss()\n",
    "        result = mlml(out, batch)\n",
    "        #CEloss = nn.CrossEntropyLoss()\n",
    "        #result = CEloss(out, batch)\n",
    "        #MSE_loss = mse_loss(batch, out)\n",
    "#         print(\"MSE loss: {0}\".format(MSE_loss))\n",
    "        print(\"CE loss: {0}\".format(result))\n",
    "    \n",
    "#         MSE_loss.backward()\n",
    "        result.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
