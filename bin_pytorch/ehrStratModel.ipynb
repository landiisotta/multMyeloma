{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ehrModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_dim, kernel_size):\n",
    "        super(ehrModel, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_dim = emb_dim \n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.padding = int((kernel_size - 1) / 2) #input sequence length = output sequence length (if stride=dilation=1)\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.cnn = nn.Conv2d(1, 1, kernel_size=(kernel_size, emb_dim), padding=(self.padding, 0))\n",
    "        self.cnn2 = nn.Conv1d(1, 1, kernel_size=(kernel_size, 1), padding=(self.padding, 0))\n",
    "        #self.FC = nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(\"Shape original mat: {0}\".format(x.shape))\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        print(\"Size embedding matrix: {0}\".format(embeds.shape))\n",
    "        \n",
    "        original_mat = embeds\n",
    "        embeds = embeds.view(-1, 1, original_mat.shape[1], self.emb_dim) #reshape the temporal matrix with n_channels=emb_dim\n",
    "        print(\"Embedding reshaping dimension: {0}\".format(embeds.shape))\n",
    "        \n",
    "        out = F.relu(self.cnn(embeds))\n",
    "        print(\"Output cnn: {0}\".format(out.shape))\n",
    "        out = F.max_pool2d(out, kernel_size=(kernel_size, out.shape[3]), padding=(self.padding, 0))\n",
    "        print(\"Dimension after first maxpooling: {0}\".format(out.shape))\n",
    "        #out = out.view(-1, 1, out.shape[2])\n",
    "        out = F.relu(self.cnn2(out))\n",
    "        out = F.max_pool2d(out, kernel_size=(kernel_size, out.shape[3]), padding=(self.padding, 0))\n",
    "        print(\"After Convolution dimension: {0}\".format(out.shape))\n",
    "        \n",
    "        out = out.view(-1, out.shape[2]) #[N, [emb_dim * temporal_dim]] N is the batch_size\n",
    "        print(\"Reshaping dimension: {0}\".format(out.shape))\n",
    "        \n",
    "        #out = F.relu(self.FC(out))\n",
    "        print(\"Output from CNN: {0}\".format(out.shape))\n",
    "        \n",
    "        #out = out.view(-1,out.shape[1] * self.emb_dim) #[N, [emb_dim * temporal_dim]] N is the batch_size\n",
    "        print(\"Reshaping dimension: {0}\".format(out.shape))\n",
    "        \n",
    "        f_in = out.shape[1]\n",
    "        print(\"AE input vector: {0}\".format(f_in))\n",
    "        f_out = x.shape[1]\n",
    "        print(f_out)\n",
    "        ehrAE = ae(f_in, f_out)\n",
    "        #ehrAE = torch.nn.DataParallel(ehrAE, device_ids=[0, 2, 3])\n",
    "        \n",
    "        #ehrAE.cuda()\n",
    "        #out = out.cuda()\n",
    "        ehrAE.to(torch.device('cuda'))\n",
    "        out = out.to(torch.device('cuda'))\n",
    "        \n",
    "        encoded_vect, out = ehrAE(out)\n",
    "        #out = out.view(-1, 1, x.shape[1])\n",
    "        #print(ehrAE.cuda())\n",
    "        print(\"AE output dimension: {0}\".format(out.shape))\n",
    "        print(\"Dimension of the encoded vector: {0}\".format(encoded_vect.shape))\n",
    "        \n",
    "        return(original_mat, out, encoded_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ae(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ae, self).__init__()\n",
    "        self.dim_in = dim_in #input dimension (vector length)\n",
    "        self.dim_out = dim_out\n",
    "        \n",
    "        h_dim = int(dim_in / 2)\n",
    "        h2_dim = int(h_dim / 2)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(dim_in, h_dim),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(h_dim, h2_dim),\n",
    "        nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.Linear(h2_dim, h_dim),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(h_dim, dim_in),\n",
    "        nn.ReLU(True),\n",
    "        nn.Linear(dim_in, dim_out),\n",
    "        nn.ReLU(True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        encoded_vect = x\n",
    "        x = self.decoder(x)\n",
    "        #x.view(-1, 65979, 100)\n",
    "        return(encoded_vect, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
