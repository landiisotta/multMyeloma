{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN\n",
    "The architecture will contain:\n",
    "- `Conv2d`;\n",
    "- `MaxPool2d`;\n",
    "- `Rectified Linear Unit (ReLU)`;\n",
    "- View;\n",
    "- Linear layer.\n",
    "\n",
    "### Conv2d\n",
    "A convolution filter (kernel) is applied to the input by moving it based on the stride value.\n",
    "\n",
    "_Stride_ is the number of values to be skipped ($1$ by default).\n",
    "\n",
    "_Padding_ prevents the filter to stop before being applied to all the data. Basically, zeros are added to both ends of a tensor. \n",
    "\n",
    "Values in the kernel are randomly initialized and trained trhough backpropagation and gradient descent.\n",
    "\n",
    "The kernel sizes that are commonly used are 1, 3, 5, and 7. The larger the kernel size, the larger the area that it can cover. Usually, high-dimensional filters are applied to the input data in the early layers.\n",
    "\n",
    "### MaxPool2d\n",
    "After convolutional layers it is common practice to add pooling layers. They reduce the size of the feature maps and the outcomes of convolution layers.\n",
    "\n",
    "MaxPool2d acts on the data generated by each filter from the previous layer. If the kernel size is $2\\times 2$, it considers that size in the image and picks the $\\max$ of that area.\n",
    "\n",
    "Another technique that is used is __average pooling__, where the $\\max$ is replaced by the average.\n",
    "\n",
    "### ReLU\n",
    "It is best practice to add a nonlinear layer after the pooling layer, or after convolution. The nonlinear function is applied to each element of the feature maps. \n",
    "\n",
    "An example of a rectifier is the activation function: $f(x)=\\max(0,x)$.\n",
    "\n",
    "### View\n",
    "It is common practice to use a fully connected (or linear) layer at the end of most networks, when dealing with image classification problems. If we are using a two-dimensional convolution, this takes a matrix of numbers as input and outputs another matix of numbers. Hence, to apply a linear layer, we need to flatten the matrix to a vector of one-dimension.\n",
    "\n",
    "```\n",
    "x.view(-1, 320)\n",
    "```\n",
    "\n",
    "The `view` method will flatten an n-dimension tensor to a one-dimensional tensor (i.e. vector). Since the input data, after batching have dimension $32\\times 1 \\times 28 \\times 28$ (i.e. batch size x channel (BW image) x height x width), we do not want to flatten/mix data for different images, so the first argument that we pass to the function is $-1$ which correspond to saying \"avoid flattening data on the first dimension\".\n",
    "\n",
    "### Linear layer\n",
    "After flattening data we pass them through a linear layer, followed by a nonlinear activation. The `log_softmax` is the final activation and predicts the digits contained in the given image.\n",
    "\n",
    "$$\n",
    "logsoftmax(x_i) = \\log\\Big{(}\\frac{\\exp(x_i)}{\\sum_j\\exp(x_j)}\\Big{)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks can be constructed using the `torch.nn` package. An `nn.Module` contains layers and a method `forward(input)` that returns the output. `nn` depends on `autograd` to define modules and differentiate them.\n",
    "\n",
    "Once the `forward` function is defined, the `backward` function (which computes gradients) is automatically defined. The parameters learned are returned by `net.parameters()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CNN ARCHITECTURE\n",
    "##Conv2d --> MaxPool2d --> ReLU \n",
    "##Conv2d --> dropout --> MaxPool2d --> ReLU\n",
    "##view --> \n",
    "##FC --> ReLU\n",
    "##dropout --> FC --> \n",
    "##Log_softmax\n",
    "\n",
    "class cnn(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(cnn, self).__init__()\n",
    "        ##class torch.nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "        ##                      stride=1, padding=0, dilation=1, groups=1, \n",
    "        ##                      bias=True)\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        ##class torch.nn.Dropout(p=0.5, inplace=False)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        ##class torch.nn.Linear(in_features, out_features, bias=True)\n",
    "        self.l1 = nn.Linear(320, 50) #4x4x20=320 image 4x4 with 20 channels?\n",
    "        self.l2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, \n",
    "        ##                         dilation=1, return_indices=False, \n",
    "        ##                         ceil_mode=False)\n",
    "        ##torch.nn.functional.max_pool2d(input, kernel_size, stride=None, \n",
    "        ##                               padding=0, dilation=1, ceil_mode=False, \n",
    "        ##                               return_indices=False)\n",
    "        ##class torch.nn.ReLU(inplace=False)\n",
    "        ## torch.nn.functional.relu(input, inplace=False) â†’ Tensor\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.l1(x))\n",
    "        ##torch.nn.functional.dropout(input, p=0.5, training=False, inplace=False)\n",
    "        x = F.dropout(x, training=self.training) ##only in training phase\n",
    "        x = self.l2(x)\n",
    "        ##torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (drop): Dropout2d(p=0.5)\n",
      "  (l1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = cnn()\n",
    "print(model)\n",
    "##to perform computation on the GPU\n",
    "#device = torch.device(\"cuda\", if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=convolution and (Subramanian, V. Deep Learning with PyTorch: A practical approach to building neural network models using PyTorch, 2018)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
